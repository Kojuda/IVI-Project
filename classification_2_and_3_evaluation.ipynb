{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\"\"\"This code is used to create sampled datasets of the classification 2 and 3 in order to evaluate\n",
    "the false positive rate and the false negative rate. We have to label the success of the classification\n",
    "by hand before computation.\"\"\"\n",
    "\n",
    "size_sample=100\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"DATABASES/project.db\")\n",
    "\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification 2 and 3 sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data into a DataFrame\n",
    "class_2_df = pd.read_sql_query(\"SELECT * from classification_2_matching_ads\", con)\n",
    "class_3_df = pd.read_sql_query(\"SELECT * from classification_3_matching_ads\", con)\n",
    "\n",
    "class_2_df.index = class_2_df.id\n",
    "class_2_df.drop(columns=[\"id\"], inplace=True)\n",
    "class_3_df.index = class_3_df.id\n",
    "class_3_df.drop(columns=[\"id\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array of NaN\n",
    "nan_ar = np.empty(size_sample)\n",
    "nan_ar[:]=np.nan\n",
    "\n",
    "#False negatives\n",
    "c2_mod_fn=class_2_df.query(\"ids_matching == '-1' | ids_matching == '-2'\").sample(size_sample)\n",
    "c2_mod_fn[\"verification\"]=nan_ar\n",
    "\n",
    "c3_mod_fn=class_3_df.query(\"ids_matching == '-1' | ids_matching == '-2'\").sample(size_sample)\n",
    "c3_mod_fn[\"verification\"]=nan_ar\n",
    "\n",
    "#False positives\n",
    "c2_mod_fp=class_2_df.query(\"ids_matching != '-1' & ids_matching != '-2'\").sample(size_sample)\n",
    "c2_mod_fp[\"verification\"]=nan_ar\n",
    "\n",
    "c3_mod_fp=class_3_df.query(\"ids_matching != '-1' & ids_matching != '-2'\").sample(size_sample)\n",
    "c3_mod_fp[\"verification\"]=nan_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     c2_mod_fn.to_sql(\"classification_2_eval_fn\", con, if_exists=\"fail\")#fail#replace\n",
    "#     c3_mod_fn.to_sql(\"classification_3_eval_fn\", con, if_exists=\"fail\")\n",
    "#     c2_mod_fp.to_sql(\"classification_2_eval_fp\", con, if_exists=\"fail\")#fail#replace\n",
    "#     c3_mod_fp.to_sql(\"classification_3_eval_fp\", con, if_exists=\"fail\")\n",
    "# except:\n",
    "#     print(\"Samplings already exist\")"
   ]
  },
  {
   "source": [
    "# Balanced sampling through species"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#Weighted the sampling with the logarithm of the inverse frequency of the a assignation. \n",
    "\n",
    "def balanced_sample(df, size_sample) :\n",
    "    \"\"\"Create a balanced sample according to the frequency of the species. We take the \n",
    "    frequency of an assignation and we weight this assignation with the logarithm of the inverse of the \n",
    "    frequency\"\"\"\n",
    "    df=df.copy()\n",
    "    list_class=[]\n",
    "    df[\"ids_matching\"]\\\n",
    "            .apply(lambda x : list_class.extend([int(_) for _ in x.split(\";\")]))\n",
    "    freq_class=Counter(list_class)\n",
    "\n",
    "    # df[\"weights\"]=df[\"ids_matching\"]\\\n",
    "    #         .apply(lambda x : 1/ ( sum([freq_class[int(_)]/len(list_class) for _ in x.split(\";\")]) ) ) #take the inverse of the frequencies' sum\n",
    "    # df[\"weights\"]=df[\"ids_matching\"]\\\n",
    "    #         .apply(lambda x :  ( sum([1-(freq_class[int(_)]/len(list_class)) for _ in x.split(\";\")]) ) ) #take the inverse of the frequencies' sum\n",
    "\n",
    "\n",
    "    \n",
    "    df[\"weights\"]=df[\"ids_matching\"]\\\n",
    "            .apply(lambda x :  math.log(1/(sum([freq_class[int(_)]/len(list_class) for _ in x.split(\";\")])))) #take the inverse of the frequencies' sum\n",
    "\n",
    "    #Sample according to the weight\n",
    "    df=df.sample(size_sample, weights=\"weights\")\n",
    "\n",
    "    #Add a verification column\n",
    "    nan_ar = np.empty(size_sample)\n",
    "    nan_ar[:]=np.nan\n",
    "    df[\"verification\"]=nan_ar\n",
    "\n",
    "    return df\n",
    "balanced_s_class2=balanced_sample(class_2_df, size_sample)\n",
    "balanced_s_class3=balanced_sample(class_3_df, size_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write them into the SQL database\n",
    "\n",
    "try:\n",
    "    balanced_s_class2.to_sql(\"classification_2_eval\", con, if_exists=\"fail\")#fail#replace\n",
    "    balanced_s_class3.to_sql(\"classification_3_eval\", con, if_exists=\"fail\")\n",
    "except:\n",
    "    print(\"Samplings already exist\")"
   ]
  },
  {
   "source": [
    "# Rates computation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filled_2_fn = pd.read_sql_query(\"SELECT * from classification_2_eval_fn\", con)\n",
    "# filled_2_fp = pd.read_sql_query(\"SELECT * from classification_2_eval_fp\", con)\n",
    "# filled_3_fn = pd.read_sql_query(\"SELECT * from classification_3_eval_fn\", con)\n",
    "# filled_3_fp = pd.read_sql_query(\"SELECT * from classification_3_eval_fp\", con)\n",
    "\n",
    "# print(f\"\"\"\n",
    "# Classification 2 | FP rate = {filled_2_fp[\"verification\"].sum()/(2*size_sample)}, FN rate = {filled_2_fn[\"verification\"].sum()/(2*size_sample)}\\n\n",
    "# Classification 3 | FP rate = {filled_3_fp[\"verification\"].sum()/(2*size_sample)}, FN rate = {filled_3_fn[\"verification\"].sum()/(2*size_sample)}\\n\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_2 = pd.read_sql_query(\"SELECT * from classification_2_eval\", con)\n",
    "filled_3 = pd.read_sql_query(\"SELECT * from classification_3_eval\", con)\n",
    "\n",
    "def print_stat(df) :\n",
    "    tp=df.query(\"ids_matching != '-1' & ids_matching != '-2'\")[\"verification\"].astype(int).sum()\n",
    "    tn=df.query(\"ids_matching == '-1' | ids_matching == '-2'\")[\"verification\"].astype(int).sum()\n",
    "    fp=len(df.query(\"ids_matching != '-1' & ids_matching != '-2'\"))-tp\n",
    "    fn=len(df.query(\"ids_matching == '-1' | ids_matching == '-2'\"))-tn\n",
    "\n",
    "    sensitivity=tp/(tp+fn)\n",
    "    specificity=tn/(tn+fp)\n",
    "    precision=tp/(tp+fp)\n",
    "    tpr=tp/(tp+fn)\n",
    "    fpr=fp/(fp+tn)\n",
    "    tnr=tn/(tn+fp)\n",
    "    fnr=fn/(fn+tp)\n",
    "\n",
    "    print(f\"\"\"\n",
    "    \\tSensibilité\\t\\t | {sensitivity:.2f}\\n\n",
    "    (Taux vrai positif)\\n\n",
    "    \\tSpécificité\\t\\t | {specificity:.2f}\\n\n",
    "    (Taux vrai négatif)\\n\n",
    "    \\tPrécision\\t\\t | {precision:.2f}\\n\n",
    "    \\tTaux faux positif\\t | {fpr:.2f}\\n\n",
    "    \\tTaux faux négatif\\t | {fnr:.2f}\\n\n",
    "    \"\"\")\n",
    "\n",
    "print(\"Classification 2 :\\n\")\n",
    "print_stat(filled_2)\n",
    "print(\"Classification 3 :\\n\")\n",
    "print_stat(filled_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to close the connection\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}